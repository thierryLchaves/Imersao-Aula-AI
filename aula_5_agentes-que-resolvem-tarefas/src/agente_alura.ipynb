{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42cf8bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AIzaSyA8ew2ieT2zBwkWmJ7UmTQgjJreDgaFaKo'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Configurando a API key localmente do Google Gemini\n",
    "import os\n",
    "os.environ.get('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bc9ceb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Configurando o cliente da SDK do Gemini \\nfrom google import genai\\n\\nclient = genai.Client()\\n\\nMODEL_ID = \"gemini-2.0-flash'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configurando o cliente da SDK do Gemini \n",
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "MODEL_ID = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eeafd7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Pergunte ao Gemini uma informação mais recente que seu conhecimento \\nfrom IPython.display import HTML, Markdown\\n\\n# Perguntar pro modelo quando é a próxima imersão de IA ###############################################\\nresposta = client.models.generate_content(model=MODEL_ID,contents=\"Quando é a proxima imersão IA com Google Gemini da Alura?\")\\n\\n#Exibe a resposta na tela \\ndisplay(Markdown(f\"Resposta:\\n {resposta.text}\"))'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pergunte ao Gemini uma informação mais recente que seu conhecimento \n",
    "from IPython.display import HTML, Markdown\n",
    "\n",
    "# Perguntar pro modelo quando é a próxima imersão de IA ###############################################\n",
    "resposta = client.models.generate_content(model=MODEL_ID,contents=\"Quando é a proxima imersão IA com Google Gemini da Alura?\")\n",
    "\n",
    "#Exibe a resposta na tela \n",
    "display(Markdown(f\"Resposta:\\n {resposta.text}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e8438fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Pergunte ao Gemini uma informação utilizando a busca do Google como contexto \\n\\nresponse = client.models.generate_content(\\n    model=MODEL_ID, \\n    contents=\\'Quando é a proxima imersão IA com Google Gemini da Alura?\\', \\n    config={\"tools\":[{\"google_search\": {}}]}\\n)\\n\\n#Exibe a resposta na tela \\ndisplay(Markdown(f\"Resposta:\\n {resposta.text}\"))\\n# Exibe a busca\\nprint(f\"Busca realizada: {response.candidates[0].grounding_metadata.web_search_queries}\")\\n# Exibe as URLs nas quais ele se baseou\\nprint(f\"Páginas utilizadas na resposta: {\\', \\'.join([site.web.title for site in response.candidates[0].grounding_metadata.grounding_chunks])}\")\\nprint()\\ndisplay(HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content))'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pergunte ao Gemini uma informação utilizando a busca do Google como contexto \n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID, \n",
    "    contents='Quando é a proxima imersão IA com Google Gemini da Alura?', \n",
    "    config={\"tools\":[{\"google_search\": {}}]}\n",
    ")\n",
    "\n",
    "#Exibe a resposta na tela \n",
    "display(Markdown(f\"Resposta:\\n {resposta.text}\"))\n",
    "# Exibe a busca\n",
    "print(f\"Busca realizada: {response.candidates[0].grounding_metadata.web_search_queries}\")\n",
    "# Exibe as URLs nas quais ele se baseou\n",
    "print(f\"Páginas utilizadas na resposta: {', '.join([site.web.title for site in response.candidates[0].grounding_metadata.grounding_chunks])}\")\n",
    "print()\n",
    "display(HTML(response.candidates[0].grounding_metadata.search_entry_point.rendered_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e502f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar Framework ADK de agentes do Google ##################################\n",
    "# pip install -q adk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97776bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import Agent # Realiza a abstração do agent \n",
    "from google.adk.runners import Runner # O orquestrador que ira \"rodar tudo\"\n",
    "from google.adk.sessions import InMemorySessionService # A memoria interna do orquestrador \n",
    "from google.adk.tools import google_search # a tooll no caso a busca do google \n",
    "from google.genai import types #Para criar conteúdos (Content e Part)\n",
    "from google import genai\n",
    "from datetime import date\n",
    "import textwrap #Para formatar melhor a saída de texto \n",
    "from IPython.display import display, Markdown #Para exibit texto formatado no colab \n",
    "import requests # Para fazer requisições HTTP\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5f24d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar que envia uma mensagem para um agente via Runner e retorna a resposta final\n",
    "def call_agent(agent: Agent, message_text: str) -> str:\n",
    "    # Cria um serviço de sessão em memória\n",
    "    session_service = InMemorySessionService()\n",
    "    # Cria uma nova sessão (você pode personalizar os IDs conforme necessário)\n",
    "    session = session_service.create_session(app_name=agent.name, user_id=\"user1\", session_id=\"session1\")\n",
    "    # Cria um Runner para o agente\n",
    "    runner = Runner(agent=agent, app_name=agent.name, session_service=session_service)\n",
    "    # Cria o conteúdo da mensagem de entrada\n",
    "    content = types.Content(role=\"user\", parts=[types.Part(text=message_text)])\n",
    "\n",
    "    final_response = \"\"\n",
    "    # Itera assincronamente pelos eventos retornados durante a execução do agente\n",
    "    for event in runner.run(user_id=\"user1\", session_id=\"session1\", new_message=content):\n",
    "        if event.is_final_response():\n",
    "          for part in event.content.parts:\n",
    "            if part.text is not None:\n",
    "              final_response += part.text\n",
    "              final_response += \"\\n\"\n",
    "    return final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76c02f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar para exibir texto formatado em Markdown no Colab\n",
    "def to_markdown(text):\n",
    "  text = text.replace('•', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d65f6909",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "# --- Agente 1: Buscador de Notícias --- #\n",
    "##########################################\n",
    "def agente_buscador(topico,data_atual):\n",
    "    buscador = Agent(\n",
    "        name=\"agente_buscador\",\n",
    "        model= \"gemini-2.0-flash\",\n",
    "        description=\"Agente que busca informações do Google\", \n",
    "        tools=[google_search],\n",
    "        instruction=\"\"\"\n",
    "        Você é um assistente de pesquisa. A sua rarefa é usar a ferramento de busca do google (google_search).\n",
    "        Para recuperar as últimas notícias de lançamentos muito relevantes sobre o tópico abaixo. \n",
    "        Foque no máximo 5 lançamento relevantes, com base na quantidade e entusiamo das notícias sobre eles. \n",
    "        Se um tema tiver poucas notícias ou poucas reações entusiasmadas, é possível que ele não seja tão relevante assim \n",
    "        e podera ser substituído por outro que tenha mais reações ou noticias correlatas. \n",
    "        Esses lançamentos relevantes devem ser atuais, e de no máximo um mês antes da data de hoje. \n",
    "        Lembre-se o resultado de sua pesquisa deverá ser limitado a no máximo 5 nóticias apenas\n",
    "        \"\"\"\n",
    "     )\n",
    "    \n",
    "    entrada_do_agente_buscador = f\"Tópico: {topico}\\nData de hoje: {data_atual}\"\n",
    "    lancamentos = call_agent(buscador,entrada_do_agente_buscador)\n",
    "    return lancamentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d6052ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# --- Agente 2: Planejador de posts --- #\n",
    "################################################\n",
    "def agente_planejador(topico, lancamentos_buscados):\n",
    "    planejador = Agent(\n",
    "        name=\"agente_planejador\", \n",
    "        model=\"gemini-2.0-flash\", \n",
    "        description=\"Agente que planeja posts\", \n",
    "        tools=[google_search],\n",
    "        instruction=\"\"\"\n",
    "        Você é um assistente de planejador de conteúdo, especialista em redes sociais.\n",
    "        Com base na lista de lançamentos mais recentese relevantes, você deve:\n",
    "        Usar a ferramenta de busca do Google (google_search), para criar um plano sobre,\n",
    "        quais são os pontos mais relevantes, em que poderíamos, abordar em um post sobre cada um deles.\n",
    "        você também pode usar o (google_search) para encontrar mais informações sobre os temas e aprofundar mais sobre. \n",
    "        Ao final, você irá  escolher o tema mais relevante entre eles com base nas suas pesquisas e retornar esse tema, \n",
    "        seus pontos mais relevantes, e um plano com os assuntos a serem abordados no post que será escrito posteriormente. \n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    entrada_do_agente_planejador = f\"Tópico: {topico}\\nLançamentos buscados{lancamentos_buscados}\"\n",
    "    #Executa o agente \n",
    "    plano_do_post = call_agent(planejador,entrada_do_agente_planejador)\n",
    "    return plano_do_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a90b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# --- Agente 3: Retador do Post --- #\n",
    "################################################\n",
    "def agente_redator(topico,plano_de_post):\n",
    "    redator = Agent(\n",
    "        name=\"agente_redator\", \n",
    "        model=\"gemini-2.0-flash\",\n",
    "        description=\"Agente redator de posts engajadores para instagram \",\n",
    "        instruction=\"\"\"\n",
    "            Você é um Redator Criativo especializado em criar posts virais para redes sociais.\n",
    "            Você escreve posts para a empresa Alura, a maior escola online de tecnologia do Brasil.\n",
    "            Utilize o tema fornecido no plano de post e os pontos mais relevantes fornecidos e, com base nisso,\n",
    "            escreva um rascunho de post para Instagram sobre o tema indicado.\n",
    "            O post deve ser engajador, informativo, com linguagem simples e incluir 2 a 4 hashtags no final.\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    entrada_do_agente_retador = f\"Tópico: {topico}\\nPlano de post: {plano_de_post}\"\n",
    "    #Executa o agente \n",
    "    rascunho = call_agent(redator,entrada_do_agente_retador)\n",
    "    return rascunho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "86802244",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################\n",
    "# --- Agente 4: Revisador de Qualidade --- #\n",
    "################################################\n",
    "def agente_revisor(topico, rascunho_gerado):\n",
    "    revisor = Agent(\n",
    "        name=\"agente_revisor\",\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        description=\"Agente revisor de post para redes sociais.\",\n",
    "        instruction=\"\"\"Você é um Editor e Revisor de Conteúdo meticuloso, especializado em posts para redes sociais, com foco no Instagram.\n",
    "            Por ter um público jovem, entre 18 e 30 anos, use um tom de escrita adequado.\n",
    "            Revise o rascunho de post de Instagram abaixo sobre o tópico indicado, verificando clareza, concisão, correção e tom.\n",
    "            Se o rascunho estiver bom, responda apenas 'O rascunho está ótimo e pronto para publicar!'.\n",
    "            Caso haja problemas, aponte-os e sugira melhorias.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    entrada_do_agente_revisor = f\"Tópico: {topico}\\nRascunho: {rascunho_gerado}\"\n",
    "    # Executa o agente\n",
    "    texto_revisado = call_agent(revisor,entrada_do_agente_revisor)\n",
    "    return texto_revisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bd4cceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Iniciando o Sistema de Criação de Posts para Instagram com 4 Agentes 🚀\n",
      "Maravilha! Vamos então criar o post sobre novidades em Agentes de IA\n",
      "\n",
      "--- 📝 Resultado do Agente 1 (Buscador) ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "> Aqui estão algumas notícias recentes sobre lançamentos de Agentes de IA:\n",
       "> \n",
       "> \n",
       "> Com base nas notícias mais recentes e relevantes sobre agentes de IA, aqui estão 5 lançamentos e tendências notáveis:\n",
       "> \n",
       "> 1.  **IBM watsonx Orchestrate:** A IBM anunciou atualizações para o watsonx Orchestrate, oferecendo soluções para integrar, personalizar e implementar agentes de IA. Inclui um Agent Catalog que simplifica a implantação de agentes pré-construídos para RH, vendas e compras, integrados com mais de 80 aplicações empresariais.\n",
       "> 2.  **Microsoft Copilot Studio:** Plataforma da Microsoft para criar agentes de IA de conversação personalizados, utilizando IA generativa e integrando-se com o Microsoft 365 e Azure.\n",
       "> 3.  **Salesforce Agentforce:** A Salesforce está focando em agentes de IA com o Agentforce, uma camada em sua plataforma que permite às empresas criar agentes de IA que atuam autonomamente em várias funções de negócios, como atendimento ao cliente e qualificação de leads.\n",
       "> 4.  **OpenAI GPT-4.1 e GPT-4.1 Mini:** A OpenAI lançou os modelos GPT-4.1 e GPT-4.1 Mini para usuários do ChatGPT. O GPT-4.1 oferece desempenho mais rápido e melhorias em programação, enquanto o GPT-4.1 Mini está acessível a todos os usuários.\n",
       "> 5.  **Crescimento do Mercado de Agentes de IA:** O mercado global de agentes de IA deve atingir US$ 52,62 bilhões até 2030, impulsionado pela necessidade de automação eficiente e decisões mais rápidas.\n",
       "> \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "\n",
      "--- 📝 Resultado do Agente 2 (Planejador) ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "> Okay, com base nas notícias recentes sobre lançamentos de Agentes de IA, vou criar um plano para posts de redes sociais sobre cada um deles, identificar o tema mais relevante e fornecer um plano detalhado para um post sobre esse tema.\n",
       "> \n",
       "> \n",
       "> Com base nas pesquisas, o tema mais relevante para um post de rede social é:\n",
       "> \n",
       "> **OpenAI GPT-4.1 e GPT-4.1 Mini:** Estes lançamentos recentes oferecem desempenho aprimorado, especialmente em tarefas de codificação e seguimento de instruções, com o GPT-4.1 Mini acessível a todos os usuários. As melhorias nos modelos GPT-4.1 os tornam consideravelmente mais eficazes no suporte a agentes ou sistemas que podem realizar tarefas de forma independente em nome dos usuários.\n",
       "> \n",
       "> ### Pontos Relevantes:\n",
       "> \n",
       "> *   **Desempenho Aprimorado:** O GPT-4.1 oferece melhorias significativas em relação aos modelos anteriores, especialmente em codificação e seguimento de instruções.\n",
       "> *   **Acessibilidade:** O GPT-4.1 Mini é acessível a todos os usuários.\n",
       "> *   **Codificação:** O GPT-4.1 demonstra melhorias nas tarefas de codificação.\n",
       "> *   **Janela de Contexto:** A família GPT-4.1 suporta até 1 milhão de tokens de contexto.\n",
       "> *   **Eficiência:** Modelos como o GPT-4.1 Mini oferecem menor latência e custo reduzido.\n",
       "> \n",
       "> ### Plano de Postagem:\n",
       "> \n",
       "> 1.  **Título:** \"OpenAI Lança GPT-4.1 e GPT-4.1 Mini: O Que Você Precisa Saber\"\n",
       "> 2.  **Imagem/Vídeo:**\n",
       ">     *   Uma imagem mostrando as capacidades de codificação do GPT-4.1.\n",
       ">     *   Um vídeo curto explicando as diferenças entre os modelos GPT-4.1, GPT-4.1 Mini e GPT-4.1 Nano.\n",
       "> 3.  **Conteúdo:**\n",
       ">     *   **Introdução:**\n",
       ">         *   Anúncio do lançamento dos modelos GPT-4.1 e GPT-4.1 Mini pela OpenAI.\n",
       ">         *   Destaque que o GPT-4.1 é especializado em tarefas de codificação e seguimento de instruções.\n",
       ">         *   Mencione que o GPT-4.1 Mini é uma versão mais acessível e eficiente.\n",
       ">     *   **Desempenho Aprimorado:**\n",
       ">         *   Explique como o GPT-4.1 melhora o desempenho em tarefas de codificação, com pontuações de 54.6% no SWE-bench Verified.\n",
       ">         *   Destaque as melhorias no seguimento de instruções, com um aumento de 10.5% no benchmark MultiChallenge da Scale.\n",
       ">     *   **Acessibilidade e Eficiência do GPT-4.1 Mini:**\n",
       ">         *   Enfatize que o GPT-4.1 Mini está disponível para todos os usuários.\n",
       ">         *   Explique como ele oferece um desempenho quase igual ao do modelo completo, mas com menor latência e custo.\n",
       ">     *   **Janela de Contexto e Aplicações:**\n",
       ">         *   Informe que os modelos GPT-4.1 suportam até 1 milhão de tokens de contexto, permitindo o processamento de grandes volumes de texto.\n",
       ">         *   Sugira aplicações para desenvolvedores que precisam de melhor desempenho, contexto mais longo e seguimento de instruções mais previsível.\n",
       ">     *   **Comparação com Modelos Anteriores:**\n",
       ">         *   Compare o GPT-4.1 com o GPT-4o, destacando as melhorias em codificação e compreensão de contexto longo.\n",
       ">         *   Mencione que o GPT-4.1 Mini corresponde ou excede o GPT-4o em muitas avaliações de inteligência.\n",
       ">     *   **Conclusão:**\n",
       ">         *   Incentive os usuários a explorar os novos modelos GPT-4.1 para melhorar seus projetos e aplicações.\n",
       ">         *   Convide a comunidade a compartilhar suas experiências e casos de uso com os novos modelos.\n",
       "> 4.  **Hashtags:** #IA #OpenAI #GPT4.1 #GPT4.1Mini #InteligenciaArtificial #Inovacao #Tecnologia #AIagentes #ChatGPT\n",
       "> 5.  **Chamada para Ação:** Experimente os novos modelos GPT-4.1 e compartilhe suas opiniões nos comentários!\n",
       "> \n",
       "> Este plano visa fornecer um conteúdo informativo e envolvente, destacando os principais benefícios e aplicações dos novos modelos GPT-4.1, incentivando a interação e o compartilhamento entre os seguidores.\n",
       "> \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "\n",
      "--- 📝 Resultado do Agente 3 (Redator) ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "> 🚀 **NOVIDADE QUENTE NO MUNDO DA IA!** 🚀\n",
       "> \n",
       "> A OpenAI acaba de lançar o GPT-4.1 e GPT-4.1 Mini e a Alura te conta tudo o que você precisa saber! 🤯\n",
       "> \n",
       "> 🤖 **GPT-4.1:** A estrela da codificação! Se você é dev, prepare-se para um desempenho turbinado e um \"follow the instructions\" impecável. 👨‍💻 Ele está ainda mais potente para te ajudar nos seus projetos!\n",
       "> \n",
       "> ✨ **GPT-4.1 Mini:** Acessível para TODOS! Quer experimentar o poder da IA sem gastar muito? O Mini é pra você! Eficiência máxima com menor latência e custo. 😉\n",
       "> \n",
       "> 📚 **Contexto GIGANTE:** Ambos suportam até 1 milhão de tokens! 🤯 Processamento de texto que não acaba mais!\n",
       "> \n",
       "> 🤔 **E aí, qual a diferença pro GPT-4o?** O GPT-4.1 chegou pra mostrar quem manda na codificação e no contexto longo! E o Mini? Bate de frente com o 4o em várias avaliações! 😱\n",
       "> \n",
       "> 🚀 **Tá esperando o que?** Corre pra testar os novos modelos e conta pra gente o que achou! 👇\n",
       "> \n",
       "> #IA #OpenAI #GPT4.1 #Alura #InteligenciaArtificial\n",
       "> \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n",
      "\n",
      "--- 📝 Resultado do Agente 4 (Revisor) ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "> O rascunho está bom, mas podemos fazer alguns ajustes para deixá-lo ainda mais engajador e claro para o público do Instagram:\n",
       "> \n",
       "> *   **Emojis:** Usar emojis em excesso pode distrair. Sugiro remover alguns para dar mais leveza ao texto.\n",
       "> *   **Linguagem:** Podemos usar uma linguagem mais direta e menos \"marketês\".\n",
       "> *   **Chamada para ação (CTA):** A CTA pode ser mais específica. Em vez de apenas \"Corre pra testar\", podemos sugerir algo como \"Teste o GPT-4.1 Mini e diga como ele turbinou sua produtividade!\".\n",
       "> *   **Hashtags:** Estão boas, mas poderíamos adicionar uma ou duas mais específicas para aumentar o alcance.\n",
       "> \n",
       "> **Sugestão de versão revisada:**\n",
       "> \n",
       "> 🚀 **NOVIDADE QUENTE EM IA!** 🚀\n",
       "> \n",
       "> A OpenAI lançou o GPT-4.1 e o GPT-4.1 Mini e a Alura te explica tudo! 🤯\n",
       "> \n",
       "> 🤖 **GPT-4.1:** A solução ideal para quem trabalha com código! Desempenho turbinado e instruções impecáveis. 👨‍💻 Ele está ainda mais potente para seus projetos!\n",
       "> \n",
       "> ✨ **GPT-4.1 Mini:** Quer experimentar o poder da IA gastando pouco? O Mini é pra você! Eficiência máxima, com menor latência e custo. 😉\n",
       "> \n",
       "> 📚 **Contexto GIGANTE:** Ambos suportam até 1 milhão de tokens! 🤯\n",
       "> \n",
       "> 🤔 **E o GPT-4o?** O GPT-4.1 chegou pra dominar na codificação e contexto longo! E o Mini? Bate de frente com o 4o em várias tarefas! 😱\n",
       "> \n",
       "> 🚀 **Bora testar?** Experimente o GPT-4.1 Mini e compartilhe como ele turbinou sua produtividade! 👇\n",
       "> \n",
       "> #IA #OpenAI #GPT4.1 #Alura #InteligenciaArtificial #Inovação\n",
       "> \n",
       "> Com essas pequenas mudanças, o post ficará mais direto, informativo e com uma chamada para ação mais clara.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data_de_hoje = date.today().strftime(\"%d/%m/%Y\")\n",
    "\n",
    "print(\"🚀 Iniciando o Sistema de Criação de Posts para Instagram com 4 Agentes 🚀\")\n",
    "\n",
    "# --- Obter o Tópico do Usuário ---\n",
    "topico = input(\"❓ Por favor, digite o TÓPICO sobre o qual você quer criar o post de tendências: \")\n",
    "\n",
    "# Inserir lógica do sistema de agentes ################################################\n",
    "if not topico:\n",
    "    print(\"Você esqueceu de digitar o tópico!\")\n",
    "else:\n",
    "    print(f\"Maravilha! Vamos então criar o post sobre novidades em {topico}\")\n",
    "\n",
    "    lancamentos_buscados = agente_buscador(topico, data_de_hoje)\n",
    "    print(\"\\n--- 📝 Resultado do Agente 1 (Buscador) ---\\n\")\n",
    "    display(to_markdown(lancamentos_buscados))\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "\n",
    "    plano_de_post = agente_planejador(topico, lancamentos_buscados)\n",
    "    print(\"\\n--- 📝 Resultado do Agente 2 (Planejador) ---\\n\")\n",
    "    display(to_markdown(plano_de_post))\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "\n",
    "    rascunho_de_post = agente_redator(topico, plano_de_post)\n",
    "    print(\"\\n--- 📝 Resultado do Agente 3 (Redator) ---\\n\")\n",
    "    display(to_markdown(rascunho_de_post))\n",
    "    print(\"--------------------------------------------------------------\")\n",
    "\n",
    "    post_final = agente_revisor(topico, rascunho_de_post)\n",
    "    print(\"\\n--- 📝 Resultado do Agente 4 (Revisor) ---\\n\")\n",
    "    display(to_markdown(post_final))\n",
    "    print(\"--------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
